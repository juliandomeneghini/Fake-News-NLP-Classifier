# üì∞ Classifica√ß√£o de Fake News - NLP  
**RU:** 4061848  
**Disciplina:** Processamento de Linguagem Natural (NLP)  
**Objetivo:** Treinar um modelo de aprendizado de m√°quina capaz de classificar not√≠cias como **VERDADEIRAS** ou **FALSAS** utilizando o corpus Fake.br-Corpus.

---

## üìã Descri√ß√£o do Projeto  
Este projeto implementa uma solu√ß√£o de **classifica√ß√£o bin√°ria** para identificar fake news em portugu√™s.  
A abordagem segue as etapas cl√°ssicas de **aquisi√ß√£o de dados, pr√©-processamento, modelagem e representa√ß√£o**.

O corpus utilizado √© o **[Fake.br-Corpus](https://github.com/roneysco/Fake.br-Corpus)**, j√° pr√©-processado, com remo√ß√£o de HTML, links e normaliza√ß√£o b√°sica.

O c√≥digo foi **adaptado** a partir do reposit√≥rio oficial da disciplina:  
üìå [https://github.com/N-CPUninter/NLP](https://github.com/N-CPUninter/NLP)  

Al√©m disso, s√£o geradas **nuvens de palavras** para visualizar os termos mais relevantes na classifica√ß√£o de not√≠cias verdadeiras e falsas.

---

## üõ†Ô∏è Tecnologias Utilizadas  
- **Python 3.x**  
- **Bibliotecas principais:**
  - `pandas` (manipula√ß√£o de dados)
  - `nltk` (pr√©-processamento de texto)
  - `scikit-learn` (vetoriza√ß√£o e modelagem)
  - `wordcloud` (gera√ß√£o de nuvens de palavras)
  - `matplotlib` (visualiza√ß√£o)
  - `numpy` (opera√ß√µes matem√°ticas)
- **Modelo:** Regress√£o Log√≠stica (`LogisticRegression`)

---

## üìÇ Estrutura do C√≥digo  
O c√≥digo est√° dividido em quatro etapas principais:

1. **Instala√ß√£o e Importa√ß√£o de Bibliotecas**  
   - Baixa o dataset pr√©-processado.  
   - Clona scripts auxiliares do reposit√≥rio de apoio.  

2. **Aquisi√ß√£o e Estrutura√ß√£o dos Dados**  
   - Leitura do `pre-processed.csv`.  
   - Remo√ß√£o de valores nulos.  

3. **Pr√©-Processamento dos Textos**  
   - Tokeniza√ß√£o  
   - Convers√£o para min√∫sculas  
   - Remo√ß√£o de acentos, n√∫meros, pontua√ß√µes e stopwords  
   - Stemming (radicaliza√ß√£o) com `RSLPStemmer`  
   - Truncamento para normaliza√ß√£o do tamanho dos textos  
   - Reconstru√ß√£o dos textos para vetoriza√ß√£o  

4. **Minera√ß√£o e Modelagem**  
   - Vetoriza√ß√£o TF-IDF com n-gramas (1 a 3)  
   - Treinamento da Regress√£o Log√≠stica  
   - Avalia√ß√£o da acur√°cia  

5. **Representa√ß√£o e Respostas**  
   - Extra√ß√£o dos termos mais relevantes para cada classe  
   - Gera√ß√£o de nuvens de palavras com m√°scaras (`thumbs_up` e `thumbs_down`)  

---

## üìä Resultados Obtidos  
- **Acur√°cia final:** ~89,6%  
- **Quantidade de termos para identificar not√≠cias verdadeiras:** *depende da execu√ß√£o*  
- **Quantidade de termos para identificar not√≠cias falsas:** *depende da execu√ß√£o*  

---

## üöÄ Como Executar no Google Colab  
1. Abra o Google Colab: [https://colab.research.google.com/](https://colab.research.google.com/)  
2. Crie um novo notebook.  
3. Copie e cole o c√≥digo principal do reposit√≥rio.  
4. Execute as c√©lulas na ordem.

---

## üñºÔ∏è Exemplos de Sa√≠da  

### üîµ Nuvem de Palavras - Not√≠cias Verdadeiras  
![Nuvem de Palavras Verdadeiras](nuvem_verdadeiras.png)

### üî¥ Nuvem de Palavras - Not√≠cias Falsas  
![Nuvem de Palavras Falsas](nuvem_falsas.png)

---

## üìö Refer√™ncias  
- [Fake.br-Corpus](https://github.com/roneysco/Fake.br-Corpus)  
- [Reposit√≥rio base da disciplina - N-CPUninter/NLP](https://github.com/N-CPUninter/NLP)  
- [Documenta√ß√£o NLTK](https://www.nltk.org/)  
- [Documenta√ß√£o Scikit-learn](https://scikit-learn.org/)  

---
